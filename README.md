
# Full Stack AI Engineering Platform

This repository is a showcase and evolving codebase for building and orchestrating AI systems from the ground upâ€”designed by a Full Stack AI Engineer with end-to-end expertise across mathematics, data engineering, software development, and Kubernetes-based infrastructure.

## ğŸ¯ Purpose

This project demonstrates a complete, production-grade architecture to:
- Operate an **LLM cluster** using [Ollama](https://ollama.com/) models.
- Harness GPU acceleration using the **NVIDIA GPU Operator** on Kubernetes.
- Use **Custom Resource Definitions (CRDs)** and controllers to coordinate model behaviors.
- Create an ecosystem where multiple models can collaborate to perform higher-level tasks (question answering, summarization, classification, etc.).
- Establish infrastructure-as-code patterns using **Kustomize**, **Flux**, and GitOps principles.

## ğŸ§  Vision

AI systems are rarely â€œone model fits all.â€ This project introduces a framework where **specialized AI agents (LLMs)**, hosted as services across a Kubernetes cluster, can **interoperate** to complete sophisticated tasks.

Inspired by:
- *Full-stack software engineering* principles
- *Multi-agent systems*
- *MLOps best practices*
- *Declarative infrastructure management*

---

## ğŸ”§ Architecture Overview

### ğŸ“ Repository Structure

```bash
.
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ cluster-iac/            # Infrastructure as Code (Terraform) for deploying an EKS cluster with requisite GPU support
â”‚   â”œâ”€â”€ base/                    # Base Kustomize configurations (Flux, GPU Operator, etc.)
â”‚   â”œâ”€â”€ overlays/                # Cluster-specific configurations
â”‚   â”œâ”€â”€ flux/                    # Flux GitOps setup
â”‚   â””â”€â”€ monitoring/              # Prometheus/Grafana, if used
â”‚
â”œâ”€â”€ crds/                        # Custom Resource Definitions (YAML) and Go types
â”‚   â”œâ”€â”€ ollamaagent_crd.yaml    # Defines OllamaAgent behavior/contract
â”‚   â””â”€â”€ taskorchestration_crd.yaml
â”‚
â”œâ”€â”€ controllers/                 # Golang operators/controllers (kubebuilder-based)
â”‚   â”œâ”€â”€ ollamaagent_controller.go
â”‚   â””â”€â”€ taskorchestration_controller.go
â”‚
â”œâ”€â”€ ollama-operators/            # Model server orchestration logic
â”‚   â”œâ”€â”€ agent-specialization/   # Specialized agent roles (Q&A, summarizer, etc.)
â”‚   â”œâ”€â”€ service-deployments/    # Helm or Kustomize configs for model deployments
â”‚   â””â”€â”€ collab-logic/           # Logic for inter-agent communication & orchestration
â”‚
â”œâ”€â”€ data/                        # Data pipeline logic (ETL, tokenization, chunking, etc.)
â”‚   â”œâ”€â”€ etl-pipeline/
â”‚   â””â”€â”€ example-datasets/
â”‚
â”œâ”€â”€ api/                         # API gateway and backend logic (Go or Python)
â”‚   â”œâ”€â”€ routes/                 # Task submission endpoints
â”‚   â””â”€â”€ orchestration/          # Converts user requests into CRs for processing
â”‚
â”œâ”€â”€ examples/                    # Example workflows and scenarios
â”‚   â”œâ”€â”€ question-answering/
â”‚   â”œâ”€â”€ summarization-pipeline/
â”‚   â””â”€â”€ multi-model-chat/
â”‚
â”œâ”€â”€ docs/                        # Architecture diagrams and documentation
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ ollama-crd-spec.md
â”‚   â””â”€â”€ orchestration-diagram.png
â”‚
â””â”€â”€ README.md
```

---

## ğŸ—ï¸ Infrastructure Stack

| Layer                | Technology                          | Purpose                                   |
|---------------------|--------------------------------------|-------------------------------------------|
| Container Runtime    | containerd                          | Lightweight, Kubernetes-native runtime    |
| GPU Provisioning     | NVIDIA GPU Operator                 | Automatically manage GPU drivers + toolkit |
| GitOps               | Flux                                | Declarative and auditable infra delivery  |
| K8s Package Manager  | Kustomize + Helm                    | Infra and app lifecycle management        |
| Model Hosting        | Ollama (on GPU nodes)               | LLM serving engine                        |
| Task Coordination    | Custom Resource Definitions (CRDs)  | Define and manage complex task orchestration |
| Monitoring           | Prometheus + Grafana (optional)     | Cluster and model performance observability |

---

## ğŸ§© Custom Resource Definitions (CRDs)

### `OllamaAgent`

A CRD for deploying and tracking a specific model service.

```yaml
apiVersion: ai.stack/v1alpha1
kind: OllamaAgent
metadata:
  name: summarizer-agent
spec:
  model: llama3
  role: summarizer
  resources:
    gpu: 1
    memory: "8Gi"
    cpu: "2"
  endpoint: "/summarize"
  env:
    - name: TEMPERATURE
      value: "0.7"
```

### `TaskOrchestration`

A CRD for assigning collaborative tasks to a group of agents.

```yaml
apiVersion: ai.stack/v1alpha1
kind: TaskOrchestration
metadata:
  name: answer-and-summarize
spec:
  inputText: "Summarize and answer questions based on this document."
  pipeline:
    - agentRef: qna-agent
    - agentRef: summarizer-agent
  outputTarget: s3://ai-results/outputs/
```

---

## ğŸš€ Getting Started

### Prerequisites

- Kubernetes cluster with GPU-enabled nodes (AWS EKS, GKE, or bare-metal)
- NVIDIA GPU Operator installed
- Flux installed and watching this repository
- Kubectl + Kustomize + Helm
- Golang (for controller development)

### Deployment Steps

```bash
# 1. Bootstrap cluster
cd infra/overlays/dev
kustomize build . | kubectl apply -f -

# 2. Apply CRDs
kubectl apply -f crds/

# 3. Deploy example agents
kubectl apply -f ollama-operators/service-deployments/

# 4. Submit an orchestration task
kubectl apply -f examples/question-answering/task.yaml
```

---

## ğŸ“¸ Diagrams

See `docs/architecture.md` and `docs/orchestration-diagram.png` for detailed system visuals.

---

## ğŸ¤ Contributing

This project is a personal and professional showcase. However, contributors are welcome! PRs, Issues, and suggestions encouraged.

---

## ğŸ“š Learning Goals

This project is also a journey of exploration. Through it, we aim to learn and demonstrate:

- GPU scheduling with Kubernetes
- Multi-agent AI orchestration
- Building CRDs and operators with Go
- Best practices in GitOps and cloud-native ML
- Open-source model hosting and scaling

---

## ğŸ“œ License

MIT License

---

## ğŸ”— Related Projects

- [NVIDIA GPU Operator](https://github.com/NVIDIA/gpu-operator)
- [Ollama](https://github.com/ollama/ollama)
- [Kubebuilder](https://book.kubebuilder.io/)
- [Kustomize](https://kustomize.io/)
- [Flux](https://fluxcd.io/)
